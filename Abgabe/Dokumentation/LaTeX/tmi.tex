\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{tmi}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{{images}}
\usepackage{textcomp}
\usepackage[nolist]{acronym}
\usepackage[hidelinks]{hyperref}
\usepackage{float}


\markboth{\journalname, VOL. XX, NO. XX, XXXX 2020}
{Author \MakeLowercase{\textit{et al.}}: Preparation of Papers for IEEE TRANSACTIONS ON MEDICAL IMAGING}

\begin{document}

% Abkürzungen werden hier definiert
\begin{acronym}
    \acro{cnn}[CNN]{Convolutional Neural Network} 
\end{acronym}

\title{Verarbeitung von Gesichtsaufnahmen zur Geschlechterklassifikation als Anwendung neuronaler Netze}
\author{Niklas Herhoffer, Celine Schneider, Andreas Braig
\thanks{Diese Arbeit wurde im Rahmen des Kurses TEL22AT1 erstellt.}
\thanks{Diese Arbeit wurde am 02.03.2025 eingereicht.}  
\thanks{Die Autoren sind Studierende an der Dualen Hochschule Baden-Württemberg Mannheim.}}

\maketitle

\begin{abstract}
    
\end{abstract}


\begin{IEEEkeywords}
    Neuronales Netz, Bildsegmentierung, Convolutional Neural Network, Genderklassifikation, Deep Learning
\end{IEEEkeywords}

\section{Einleitung}
\label{sec:introduction}
\IEEEPARstart{D}{iese} Arbeit befasst sich mit der Verarbeitung und Klassifikation von Gesichtsaufnahmen. Die verwendeten Daten bestehen aus Gesichtsaufnahmen von Personen unterschiedlichen Alters. 

Die erste Teilaufgabe der Arbeit besteht in der Segmentierung und Verarbeitung des Datensatzes, um die Gesichtselemente (insbesondere Augen und Mund) in den Bildern einheitlich zu positionieren. Dies wird erreicht, indem ein gleichschenkliges Dreieck mit festen Positionen für die Augen und den Mund im Bild definiert wird. 

Die zweite Teilaufgabe konzentriert sich auf die Klassifikation des Geschlechts der abgebildeten Person. Ein Convolutional Neural Network wird trainiert, um eine binäre Klassifikation zwischen Männlich (0) und Weiblich (1) durchzuführen.

Für die Implementierung wurde die Programmiersprache Python verwendet, unterstützt durch die Bibliotheken OpenCV, numpy und Pytorch.


\section{Stand der Technik}
ACHTUNG, DAS HAT DIE KATZE GESCHRIEBEN
\subsection{Bildsegmentierung}  
Die Bildsegmentierung ist eine Technik der Computer Vision, die ein digitales Bild in einzelne Pixelgruppen unterteilt, um die Objekterkennung und verwandte Aufgaben zu unterstützen.  
Traditionelle Methoden analysieren visuelle Merkmale wie Farbe oder Helligkeit, während moderne Ansätze auf Deep Learning basieren und komplexe neuronale Netze für anspruchsvolle Mustererkennung einsetzen.  
Klassische Verfahren umfassen Schwellenwertmethoden (z. B. Otsu), Kantenerkennung und Clustering-Algorithmen (z. B. K-Means).  
State-of-the-Art-Modelle wie U-Net oder Mask R-\ac{cnn} ermöglichen eine pixelgenaue Segmentierung mit hoher Präzision.  

\subsection{Neuronale Netze und Deep Learning-Frameworks}  
\acp{cnn} spielen eine zentrale Rolle in der modernen Bildverarbeitung.
Sie extrahieren Merkmale durch Faltungsoperationen und ermöglichen effektive Objekterkennung sowie Klassifikation.
Deep Learning-Frameworks wie PyTorch bieten GPU-Unterstützung für beschleunigte Berechnungen, automatische Differenzierung für effizientes Training und flexible Programmierschnittstellen.
Diese Werkzeuge erleichtern die Implementierung komplexer neuronaler Netzarchitekturen für verschiedene Bildverarbeitungsaufgaben.
OpenCV ergänzt diese Fähigkeiten durch effiziente Algorithmen für Filterung, Merkmalsextraktion und Transformationen.

\subsection{Deep Learning in der Bildanalyse}  % Das hier ist irgendwie trash
Deep Learning-Methoden, insbesondere \acp{cnn}, haben die Bildanalyse signifikant verbessert.
\acp{cnn} extrahieren hierarchische Merkmale durch Faltungsoperationen und ermöglichen effiziente Objekterkennung sowie Klassifikation.
Aktuelle Anwendungen umfassen Bildklassifizierung, Objektdetektion und semantische Segmentierung.

Transfer Learning reduziert den Trainingsaufwand durch Nutzung vortrainierter Modelle.
In der industriellen Bildverarbeitung finden Deep Learning-Techniken zunehmend Anwendung, etwa in der automatisierten Qualitätskontrolle und Werkstoffprüfung.
Die kontinuierliche Weiterentwicklung dieser Techniken verspricht weitere Fortschritte, insbesondere in der medizinischen Bildanalyse und industriellen Anwendungen.

\section{Datensatz}
In diesem Kapitel wird der verwendete Datensatz sowie die damit einhergehenden Herausforderungen beschrieben.

\subsection{Allgemeine Beschreibung des Datensatzes}
Der Datensatz besteht aus Gesichtsaufnahmen, die von Personen unterschiedlichen Alters und mit unterschiedlichen Gesichtszügen aufgenommen wurden.
Zusätzlich zu diesen Bildern umfasst der Datensatz ebenfalls zu jedem Bild eine dazugehörige Maske, sowie die tagging.json Datei.
In dieser JSON-Datei sind über die Dateinamen jeweils das Geschlecht der abgebildeten Person zugeordnet.
Hiermit lässt sich also der Datensatz in die Kategorien "männlich" und "weiblich" einteilen.

\subsection{Herausforderungen bei der Datenverarbeitung}  
Bei der Vorverarbeitung treten mehrere Herausforderungen auf: Unterschiedliche Bildgrößen, variierende Gesichtsgrößen und abweichende Positionen von Augen und Mund erfordern eine Normalisierung.
Kopfneigungen und Drehungen erschweren die Standardisierung zusätzlich. Ein besonderes Problem sind verdeckte Gesichter, etwa durch Masken, sowie extreme Gesichtsausdrücke wie weit geöffnete Münder oder herausgestreckte Zungen, die die Merkmalsextraktion beeinträchtigen.

Um diesen Herausforderungen zu begegnen, wird in der Vorverarbeitung ein Verfahren eingesetzt, bei dem die Bilder auf eine einheitliche Größe skaliert und die Augen und der Mund auf einheitliche Positionen im Bild ausgerichtet werden.
Hierfür müssen die Positionen der Augen und des Mundes mithilfe der Masken ermittelt werden.
Dies ermöglicht es dem neuronalen Netzwerk, diese markanten Punkte als Referenz für den Vergleich und das Einlernen der Unterscheidungsmerkmale der Geschlechtern zu nutzen.












\section{Implementierte Lösung}

\begin{figure}[!t]
    \centerline{\includegraphics[width=\columnwidth]{Architektur.png}}
    \caption{Darstellung der Programmarchitektur in Form eines Blockschaltbildes}
    \label{fig:architecture}
\end{figure}

\subsection{Preprocessing}
Das Preprocessing übernimmt die zentrale Aufgabe der Vorverarbeitung der Rohdaten für das Training des neuronalen Netzwerks.
Durch die Funktion \texttt{cleanup} wird zunächst sichergestellt, dass sämtliche Datensätze in den Zielordnern gelöscht werden, um eine Vermischung mit einem veralteten Datensatz zu verhindern.
Anschließend werden die Metadaten, einschließlich der Dateinamen und der Geschlechter, aus der \texttt{tag.json} extrahiert und in einem strukturierten 2D-Array gespeichert, sodass die Weiterverarbeitung der Daten erleichtert wird.
Auf Grundlage der so gewonnenen Zuordnungen zwischen Bilddateien und Geschlecht erfolgt die Trennung der Bilddaten in zwei separate Ordner - einen für männliche und einen für weibliche Gesichter.
Im nächsten Schritt wird die Funktion \texttt{freistellen} eingesetzt, um die Gesichter in den Bildern zu extrahieren.
Nach dieser Extraktion erfolgt eine Transformation, die die Gesichter auf eine standardisierte Positionierung von Augen und Mund ausrichtet, um eine konsistente Eingabe für das Modell zu gewährleisten.
Anschließend erfolgt mithilfe der Funktion \texttt{train\_test\_split} die Aufteilung der vorverarbeiteten Bilddaten in Trainings- und Testdatensätze.
Hierbei wird ein zufällig ausgewählter Prozentsatz der Bilder in den Testdatensatz überführt.
Dieser Schritt ist entscheidend, um eine objektive Evaluierung des Modells zu ermöglichen und Überanpassung (Overfitting) zu vermeiden, wie in Abschnitt \ref{sec:overfitting} beschrieben.

\subsection{Segmentierung}
Im Segmentierungsschritt werden die Gesichtselemente wie Augen, Nase und Mund positioniert und normiert, um das Modell mit konsistenten Eingabedaten zu füttern.

\subsection{\ac{cnn} Modell}
Das \ac{cnn} wird verwendet, um das Geschlecht der abgebildeten Person zu klassifizieren. Hierbei kommen mehrere Convolutional Layers und Pooling Layers zum Einsatz, um aus den Eingabebildern tiefere Merkmale zu extrahieren.

\section{Lösungsansätze im Vergleich}

In diesem Kapitel werden fünf Ansätze zur Implementierung des CNN vorgestellt. Insgesamt umfasst die Versuchsreihe 23 trainierte neuronale Netze unterschiedlicher einstellungen und Dimensionen.
Um der Anforderung an diese Dokumentation gerecht zu werden fällt die Wahl auf 5 Modelle die sowohl den Fortschritt, als auch den Wissensgewinn repräsentieren.

\begin{figure}[H]
    \centerline{\includegraphics[width=\columnwidth]{Erfolg_Dauer.png}}
    \caption{Vergleichsdiagramm zwischen Erfolgsquote des jeweiligen Modells im Test gegenüber der Dauer einer Trainingsepoche.}
    \label{fig:compareGraph}
\end{figure}

\subsection{Zeilicher Verlauf und Wissensgewinn}
Als Grundlage für das Design des neuralen Netz dient ein im Labor verwendeter Python-Pytorch Code. Dieser Code ist in seinen Parametern ergänzt, um 



% \begin{figure}[!t]
%     \centerline{\includegraphics[width=\columnwidth]{Andi/binaere_klassifikation.png}}
%     \caption{Beispiel für die binäre Klassifikation.}
%     \label{fig:binaere_klassifikation}
% \end{figure}

% \begin{figure}[!t]
%     \centerline{\includegraphics[width=\columnwidth]{Andi/Loss_Acc_Gewinner.png}}
%     \caption{Trainingslog des \ac{cnn} Modells, welches im Test die besten Ergebnisse erzielt hat.}
%     \label{fig:winner}
% \end{figure}

\subsection{Training und Evaluation}
Das Training des \ac{cnn}-Modells wird erläutert, ebenso wie die Evaluierung der Modellleistung anhand von Metriken wie der Genauigkeit und dem Verlust.

\subsubsection{Overfitting}
\label{sec:overfitting}

\section{Fazit}
Im Fazit werden die Ergebnisse der Arbeit zusammengefasst und diskutiert. Es wird reflektiert, inwiefern die gesetzten Ziele erreicht wurden und welche Verbesserungspotenziale noch bestehen.








\appendices

\section*{Appendix und die Nutzung von ergänzenden Dateien}

\section*{Danksagung}

\end{document}
